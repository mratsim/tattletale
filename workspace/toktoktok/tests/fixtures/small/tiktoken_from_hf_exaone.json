[
  {
    "name": "chinese",
    "text": "‰Ω†Â•Ω‰∏ñÁïå",
    "token_ids": [
      80898,
      85428,
      86134
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "japanese",
    "text": "„Åì„Çì„Å´„Å°„ÅØ",
    "token_ids": [
      105684
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "korean",
    "text": "ÏïàÎÖïÌïòÏÑ∏Ïöî ÏÑ∏Í≥Ñ",
    "token_ids": [
      125710,
      3539
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "russian",
    "text": "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä",
    "token_ids": [
      105560,
      32146,
      14184,
      103207
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "hebrew",
    "text": "◊©◊ú◊ï◊ù ◊¢◊ï◊ú◊ù",
    "token_ids": [
      41346,
      31185,
      146160,
      145515,
      145720,
      59714
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "khmer",
    "text": "·ûü·ûΩ·ûü·üí·ûè·û∏·ûñ·û∑·ûó·ûñ·ûõ·üÑ·ûÄ",
    "token_ids": [
      35149,
      615,
      35149,
      483,
      35149,
      615,
      145773,
      599,
      35149,
      478,
      35149,
      606,
      35149,
      477,
      35149,
      607,
      35149,
      606,
      35149,
      611,
      68853,
      588,
      35149,
      584
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "emoji",
    "text": "Hello üåç World! üéâ",
    "token_ids": [
      33381,
      150657,
      597,
      5542,
      362,
      14901,
      598,
      593
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "mixed_cjk",
    "text": "Hello ‰∏ñÁïå „Åì„Çì„Å´„Å°„ÅØ ÏïàÎÖï",
    "token_ids": [
      33381,
      37585,
      17496,
      98676,
      102647,
      7563
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "hello_world",
    "text": "Hello, world!",
    "token_ids": [
      33381,
      373,
      2711,
      362
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "greek_basic",
    "text": "ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ Œ∫Œ±Œπ ŒºŒ±Œ∏Œ∑ŒºŒ±œÑŒπŒ∫Œ¨",
    "token_ids": [
      146686,
      146157,
      147534,
      41851,
      25039,
      62943,
      4625,
      9546,
      39658,
      19384,
      56965,
      145710,
      25039
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "greek_alphabet",
    "text": "Œë Œ± Œí Œ≤ Œì Œ≥ Œî Œ¥ Œï Œµ Œñ Œ∂ Œó Œ∑ Œò Œ∏ Œô Œπ Œö Œ∫ Œõ Œª Œú Œº Œù ŒΩ Œû Œæ Œü Œø Œ† œÄ Œ° œÅ Œ£ œÉ Œ§ œÑ Œ• œÖ Œ¶ œÜ Œß œá Œ® œà Œ© œâ",
    "token_ids": [
      146683,
      6538,
      2031,
      602,
      7498,
      28078,
      12215,
      13384,
      13972,
      146891,
      15448,
      2031,
      606,
      44980,
      146892,
      23046,
      57718,
      15496,
      2031,
      609,
      2031,
      479,
      146893,
      16445,
      37422,
      13370,
      146894,
      4625,
      2031,
      613,
      19291,
      2031,
      614,
      28847,
      146895,
      51194,
      50198,
      13553,
      2031,
      456,
      18819,
      33354,
      12697,
      146887,
      12412,
      2031,
      460,
      146054,
      34695,
      14704,
      2031,
      462,
      25735,
      55237,
      29070,
      23604,
      17917
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_endo",
    "text": "Check the Endomorphism for p mod 3 == 1",
    "token_ids": [
      15907,
      629,
      3442,
      6844,
      46038,
      791,
      644,
      1404,
      582,
      380,
      3133,
      582,
      378
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_cube_roots",
    "text": "x¬≥‚àí1=0 <=> (x‚àí1)(x¬≤+x+1) = 0, if x != 1, x solves (x¬≤+x+1) = 0 <=> x = (-1¬±‚àö3)/2",
    "token_ids": [
      449,
      70837,
      10181,
      378,
      390,
      377,
      14888,
      391,
      688,
      449,
      10181,
      378,
      70495,
      449,
      70400,
      72460,
      372,
      378,
      370,
      801,
      582,
      377,
      373,
      124402,
      70415,
      582,
      378,
      373,
      1262,
      47418,
      688,
      449,
      70400,
      72460,
      372,
      378,
      370,
      801,
      582,
      377,
      14888,
      391,
      1262,
      801,
      6169,
      378,
      148513,
      380,
      70439,
      379
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_curve",
    "text": "y¬≤ = x¬≥ + b, and y¬≤ = (xùúë)¬≥ + b <=> y¬≤ = x¬≥ + b (with ùúë¬≥ == 1) so we are still on the curve",
    "token_ids": [
      450,
      70400,
      801,
      1262,
      70837,
      1096,
      655,
      373,
      116324,
      70400,
      801,
      688,
      449,
      82384,
      370,
      70837,
      1096,
      655,
      14888,
      391,
      829,
      70400,
      801,
      1262,
      70837,
      1096,
      655,
      688,
      6346,
      582,
      82384,
      70837,
      3133,
      582,
      378,
      370,
      1329,
      115472,
      2669,
      115365,
      10135
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_lambda",
    "text": "Œª·µ©¬≤ + Œª·µ© + 1 ‚â° 0 (mod r) and ùúë¬≤ + ùúë + 1 ‚â° 0 (mod p)",
    "token_ids": [
      20341,
      81183,
      464,
      70400,
      1096,
      13370,
      81183,
      464,
      1096,
      582,
      378,
      52544,
      582,
      377,
      688,
      10735,
      856,
      370,
      686,
      582,
      82384,
      70400,
      1096,
      582,
      82384,
      1096,
      582,
      378,
      52544,
      582,
      377,
      688,
      10735,
      644,
      370
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_scalar",
    "text": "[a]P to represent P+P+ .... + P",
    "token_ids": [
      71945,
      422,
      409,
      119501,
      854,
      151542,
      372,
      20213,
      1096,
      854
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_bilinear",
    "text": "e: ùîæ1 x ùîæ2 -> ùîæt that map is bilinear e([a]P, [b]Q) = e(P, Q)·µÉ·µá",
    "token_ids": [
      430,
      387,
      84210,
      604,
      484,
      378,
      1262,
      84210,
      604,
      484,
      379,
      4461,
      84210,
      604,
      484,
      445,
      817,
      5026,
      772,
      67085,
      711,
      57946,
      426,
      422,
      409,
      373,
      974,
      427,
      422,
      410,
      370,
      801,
      711,
      71208,
      373,
      2039,
      370,
      81183,
      587,
      81183,
      591
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_srs",
    "text": "srs_g1: [[1]‚ÇÅ, [œÑ]‚ÇÅ, [œÑ¬≤]‚ÇÅ, ... [œÑ‚Åø‚Åª¬π]‚ÇÅ] also called powers of tau",
    "token_ids": [
      444,
      9681,
      70682,
      378,
      387,
      71254,
      378,
      422,
      70752,
      373,
      974,
      13400,
      422,
      70752,
      373,
      974,
      13400,
      70400,
      422,
      70752,
      373,
      4377,
      974,
      13400,
      151201,
      72274,
      73253,
      422,
      70752,
      422,
      121740,
      122462,
      7192
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_commitment",
    "text": "commit(srs_g1, blob) -> commitment C = ‚àë blob·µ¢.srs_g1·µ¢ = ‚àë [blob·µ¢.œÑ‚Å±]‚ÇÅ = [p(œÑ)]‚ÇÅ",
    "token_ids": [
      39512,
      70429,
      9681,
      70682,
      378,
      373,
      19655,
      370,
      4461,
      15529,
      784,
      801,
      79473,
      19655,
      81183,
      457,
      70455,
      9681,
      70682,
      378,
      81183,
      457,
      801,
      79473,
      974,
      78472,
      81183,
      457,
      375,
      13400,
      70969,
      471,
      422,
      70752,
      801,
      974,
      441,
      151171,
      70790,
      70752
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_witness",
    "text": "w(x, z) = (p(x) - p(z)) / (x-z)",
    "token_ids": [
      448,
      70407,
      373,
      1782,
      370,
      801,
      688,
      441,
      70407,
      370,
      672,
      644,
      71059,
      19146,
      841,
      688,
      449,
      72000,
      370
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_verification",
    "text": "e([proof]‚ÇÅ, [œÑ]‚ÇÇ - [z]‚ÇÇ) = e(C - [y]‚ÇÅ, [1]‚ÇÇ)",
    "token_ids": [
      430,
      57946,
      30547,
      422,
      70752,
      373,
      974,
      13400,
      422,
      70757,
      672,
      974,
      451,
      422,
      70757,
      370,
      801,
      711,
      70909,
      672,
      974,
      450,
      422,
      70752,
      373,
      974,
      378,
      422,
      70757,
      370
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "ecc_lagrange",
    "text": "œâ ‚àà ùîΩr a root of unity of order n, i.e. œâ‚Åø = 1",
    "token_ids": [
      29498,
      10072,
      84210,
      604,
      483,
      443,
      619,
      120011,
      22079,
      124199,
      709,
      373,
      1239,
      70533,
      375,
      17917,
      151201,
      801,
      582,
      378
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "group_basics",
    "text": "A group is a set of elements with a binary operation called the group law with a neutral element and an inverse.",
    "token_ids": [
      394,
      2427,
      115367,
      115582,
      5449,
      115380,
      12321,
      6207,
      116035,
      2427,
      2848,
      115380,
      12905,
      4745,
      115668,
      18069,
      375
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "field_basics",
    "text": "A field is a set of elements with two group laws, addition and multiplication, with corresponding inverse properties.",
    "token_ids": [
      394,
      2677,
      115367,
      115582,
      5449,
      116293,
      2427,
      8004,
      373,
      124118,
      35531,
      373,
      851,
      6320,
      18069,
      4971,
      375
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "finite_field",
    "text": "ùîΩr is a finite-field of prime order r",
    "token_ids": [
      71068,
      604,
      483,
      443,
      115367,
      10295,
      75167,
      670,
      6177,
      2244,
      856
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "cyclic_group",
    "text": "The group can be cyclic, i.e. all elements of the group can be generated by repeatedly applying the group law.",
    "token_ids": [
      1320,
      2427,
      115377,
      26003,
      373,
      1239,
      70533,
      375,
      1176,
      120634,
      2427,
      115377,
      119076,
      20190,
      12722,
      118987,
      2848,
      375
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "additive_notation",
    "text": "[a]P to represent P+P+ .... + P, applying the group law a times, i.e. the scalar multiplication.",
    "token_ids": [
      71945,
      422,
      409,
      119501,
      854,
      151542,
      372,
      20213,
      1096,
      854,
      373,
      12722,
      118987,
      2848,
      619,
      3058,
      373,
      1239,
      70533,
      375,
      629,
      19245,
      35531,
      375
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_prover",
    "text": "Prover computes witness polynomial w(x, z) = (p(x) - p(z)) / (x-z)",
    "token_ids": [
      3878,
      818,
      56931,
      9275,
      20234,
      642,
      70407,
      373,
      1782,
      370,
      801,
      688,
      441,
      70407,
      370,
      672,
      644,
      71059,
      19146,
      841,
      688,
      449,
      72000,
      370
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_verifier",
    "text": "Verifier checks proof.(œÑ-z) = p(œÑ) - y using bilinear pairing",
    "token_ids": [
      23063,
      11933,
      16505,
      7606,
      21339,
      13400,
      72000,
      370,
      801,
      644,
      151171,
      370,
      672,
      829,
      1935,
      67085,
      37344
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_fiat_shamir",
    "text": "To make the protocol non-interactive, z may be computed via the Fiat-Shamir heuristic.",
    "token_ids": [
      3992,
      116017,
      8302,
      2406,
      72746,
      7447,
      373,
      1782,
      115416,
      13570,
      116664,
      898,
      9404,
      84081,
      788,
      861,
      44719,
      375
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_schwartz",
    "text": "According to the Schwartz-zippel Lemma it is cryptographically unlikely that this equation holds",
    "token_ids": [
      117470,
      54789,
      72000,
      3584,
      718,
      14701,
      115382,
      14165,
      6102,
      2978,
      17750,
      115655,
      7596,
      10424
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_srs_g1",
    "text": "srs_g1: [[1]‚ÇÅ, [œÑ]‚ÇÅ, [œÑ¬≤]‚ÇÅ, ... [œÑ‚Åø‚Åª¬π]‚ÇÅ] also called powers of tau, with a bounded degree n-1",
    "token_ids": [
      444,
      9681,
      70682,
      378,
      387,
      71254,
      378,
      422,
      70752,
      373,
      974,
      13400,
      422,
      70752,
      373,
      974,
      13400,
      70400,
      422,
      70752,
      373,
      4377,
      974,
      13400,
      151201,
      72274,
      73253,
      422,
      70752,
      422,
      121740,
      122462,
      7192,
      373,
      115380,
      17339,
      5841,
      709,
      374,
      378
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_srs_g2",
    "text": "srs_g2: [[1]‚ÇÇ, [œÑ]‚ÇÇ]",
    "token_ids": [
      444,
      9681,
      70682,
      379,
      387,
      71254,
      378,
      422,
      70757,
      373,
      974,
      13400,
      422,
      70757,
      422
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_trust_setup",
    "text": "œÑ and its powers are secrets that no one knows, we only work with [œÑ‚Å±]‚ÇÅ and [œÑ]‚ÇÇ not with œÑ directly",
    "token_ids": [
      13400,
      115586,
      13685,
      937,
      27782,
      817,
      116255,
      10612,
      373,
      124518,
      116728,
      974,
      13400,
      70969,
      471,
      422,
      70752,
      686,
      974,
      13400,
      422,
      70757,
      1017,
      851,
      12412,
      5576
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "pcs_monomial",
    "text": "p(x) = blob‚ÇÄ + blob‚ÇÅ x + blob‚ÇÇ x¬≤ + ... + blob‚Çô‚Çã‚ÇÅ x‚Åø‚Åª¬π",
    "token_ids": [
      441,
      70407,
      370,
      801,
      19655,
      71175,
      1096,
      19655,
      70752,
      1262,
      1096,
      19655,
      70757,
      1262,
      70400,
      1096,
      4377,
      1096,
      19655,
      75622,
      70473,
      595,
      70752,
      1262,
      151201,
      72274,
      73253
    ],
    "tokenizer": "exaone-tokenizer.json"
  },
  {
    "name": "sanguozhi_paragraph",
    "text": "Á¥Ö„ÄÇÁôΩ\nÈ´ÆÊºÅÊ®µÊ±üÊ∏ö‰∏äÔºåÊÖ£ÁúãÁßãÊúàÊò•È¢®„ÄÇ‰∏ÄÂ£∫ÊøÅÈÖíÂñúÁõ∏ÈÄ¢ÔºöÂè§‰ªäÂ§öÂ∞ë‰∫ãÔºåÈÉΩ‰ªòÁ¨ëË´á‰∏≠„ÄÇ\n\n„ÄÄ„ÄÄË©±Ë™™Â§©‰∏ãÂ§ßÂã¢ÔºåÂàÜ‰πÖÂøÖÂêàÔºåÂêà‰πÖÂøÖÂàÜÔºöÂë®Êú´‰∏ÉÂúãÂàÜÁà≠ÔºåÂπ∂ÂÖ•ÊñºÁß¶„ÄÇÂèäÁß¶ÊªÖ‰πãÂæåÔºåÊ•ö\n„ÄÅÊº¢ÂàÜÁà≠ÔºåÂèàÂπ∂ÂÖ•ÊñºÊº¢„ÄÇÊº¢ÊúùËá™È´òÁ•ñÊñ¨ÁôΩËõáËÄåËµ∑Áæ©Ôºå‰∏ÄÁµ±Â§©‰∏ã„ÄÇÂæå‰æÜÂÖâÊ≠¶‰∏≠ËààÔºåÂÇ≥Ëá≥Áçª\nÂ∏ùÈÅÇÂàÜÁÇ∫‰∏âÂúã„ÄÇÊé®ÂÖ∂Ëá¥‰∫Ç‰πãÁî±ÔºåÊÆÜÂßãÊñºÊ°ì„ÄÅÈùà‰∫åÂ∏ù„ÄÇÊ°ìÂ∏ùÁ¶ÅÈåÆÂñÑÈ°ûÔºåÂ¥á‰ø°ÂÆ¶ÂÆò„ÄÇÂèäÊ°ì\nÂ∏ùÂ¥©ÔºåÈùàÂ∏ùÂç≥‰ΩçÔºåÂ§ßÂ∞áËªçÁ´áÊ≠¶",
    "token_ids": [
      92089,
      71245,
      85722,
      560,
      110172,
      36537,
      585,
      36912,
      475,
      86766,
      35033,
      610,
      24222,
      70775,
      95095,
      85486,
      89403,
      41248,
      87168,
      69181,
      93715,
      30589,
      480,
      66849,
      585,
      86305,
      86478,
      50116,
      110217,
      71918,
      58586,
      85506,
      90211,
      25201,
      70775,
      41481,
      85735,
      86280,
      87461,
      19239,
      72305,
      560,
      82360,
      82360,
      85789,
      86308,
      102264,
      24212,
      88993,
      70775,
      24067,
      86933,
      85659,
      29052,
      70775,
      29052,
      86933,
      85659,
      24067,
      71918,
      85962,
      88166,
      88262,
      24721,
      24067,
      99707,
      70775,
      79698,
      31263,
      86748,
      94354,
      71245,
      85563,
      94354,
      95364,
      106265,
      70775,
      91919,
      560,
      73088,
      98062,
      24067,
      99707,
      70775,
      86106,
      79698,
      31263,
      86748,
      98062,
      71245,
      98062,
      59939,
      70238,
      44992,
      92145,
      12266,
      467,
      85722,
      103818,
      85501,
      85522,
      39320,
      70775,
      24516,
      49960,
      102264,
      71245,
      30018,
      54602,
      85758,
      87114,
      19239,
      89374,
      70775,
      91135,
      85904,
      86839,
      481,
      560,
      66660,
      111342,
      24067,
      85820,
      58417,
      24721,
      71245,
      85817,
      80172,
      86394,
      105844,
      50916,
      44011,
      70775,
      38600,
      590,
      75122,
      86748,
      53709,
      603,
      73088,
      95039,
      58670,
      66660,
      71245,
      53709,
      603,
      66660,
      88952,
      86079,
      468,
      87139,
      52645,
      70775,
      109989,
      53539,
      9839,
      461,
      52205,
      71245,
      85563,
      53709,
      603,
      560,
      66660,
      99126,
      70775,
      95039,
      66660,
      86225,
      32560,
      70775,
      24212,
      87229,
      38376,
      24101,
      591,
      87114
    ],
    "tokenizer": "exaone-tokenizer.json"
  }
]