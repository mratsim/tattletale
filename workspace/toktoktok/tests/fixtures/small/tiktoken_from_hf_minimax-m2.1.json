[
  {
    "name": "chinese",
    "text": "ä½ å¥½ä¸–ç•Œ",
    "token_ids": [
      56658,
      4083
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "japanese",
    "text": "ã“ã‚“ã«ã¡ã¯",
    "token_ids": [
      36334
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "korean",
    "text": "ì•ˆë…•í•˜ì„¸ìš” ì„¸ê³„",
    "token_ids": [
      11878,
      175354,
      36372
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "russian",
    "text": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€",
    "token_ids": [
      45775,
      31016,
      158440
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "hebrew",
    "text": "×©×œ×•× ×¢×•×œ×",
    "token_ids": [
      63569,
      44776,
      33154,
      157,
      121556,
      33154,
      156,
      104990
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "khmer",
    "text": "áŸá½áŸáŸ’áá¸á–á·á—á–á›áŸ„á€",
    "token_ids": [
      76300,
      159,
      76300,
      189,
      76300,
      159,
      157246,
      146,
      76300,
      143,
      76300,
      184,
      76300,
      150,
      76300,
      183,
      76300,
      151,
      76300,
      150,
      76300,
      155,
      157246,
      132,
      76300,
      128
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "emoji",
    "text": "Hello ğŸŒ World! ğŸ‰",
    "token_ids": [
      19739,
      9753,
      149144,
      5476,
      33,
      171182,
      137
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "mixed_cjk",
    "text": "Hello ä¸–ç•Œ ã“ã‚“ã«ã¡ã¯ ì•ˆë…•",
    "token_ids": [
      19739,
      112507,
      32,
      36334,
      15194,
      124558
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "hello_world",
    "text": "Hello, world!",
    "token_ids": [
      19739,
      44,
      2035,
      33
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "greek_basic",
    "text": "Î•Î»Î»Î·Î½Î¹ÎºÎ¬ ÎºÎ±Î¹ Î¼Î±Î¸Î·Î¼Î±Ï„Î¹ÎºÎ¬",
    "token_ids": [
      126137,
      131433,
      128593,
      90996,
      43292,
      122987,
      25008,
      11780,
      44497,
      33128,
      112062,
      20669,
      90996,
      43292
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "greek_alphabet",
    "text": "Î‘ Î± Î’ Î² Î“ Î³ Î” Î´ Î• Îµ Î– Î¶ Î— Î· Î˜ Î¸ Î™ Î¹ Îš Îº Î› Î» Îœ Î¼ Î Î½ Î Î¾ ÎŸ Î¿ Î  Ï€ Î¡ Ï Î£ Ïƒ Î¤ Ï„ Î¥ Ï… Î¦ Ï† Î§ Ï‡ Î¨ Ïˆ Î© Ï‰",
    "token_ids": [
      98059,
      27562,
      6437,
      146,
      40385,
      101684,
      61543,
      57855,
      49007,
      181857,
      53726,
      6437,
      150,
      6437,
      182,
      6437,
      151,
      130353,
      6437,
      152,
      64461,
      6437,
      153,
      6437,
      185,
      174932,
      45019,
      6437,
      155,
      63233,
      6437,
      156,
      25008,
      6437,
      157,
      89868,
      6437,
      158,
      6437,
      190,
      6437,
      159,
      99767,
      148537,
      41005,
      6437,
      161,
      126960,
      119224,
      46983,
      193056,
      32345,
      6437,
      165,
      13726,
      133,
      178559,
      90799,
      6437,
      167,
      121592,
      6437,
      168,
      196763,
      153434,
      125358
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_endo",
    "text": "Check the Endomorphism for p mod 3 == 1",
    "token_ids": [
      10309,
      275,
      1210,
      6004,
      94591,
      360,
      273,
      1057,
      32,
      51,
      2044,
      32,
      49
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_cube_roots",
    "text": "xÂ³âˆ’1=0 <=> (xâˆ’1)(xÂ²+x+1) = 0, if x != 1, x solves (xÂ²+x+1) = 0 <=> x = (-1Â±âˆš3)/2",
    "token_ids": [
      120,
      41672,
      14919,
      49,
      61,
      48,
      11161,
      62,
      359,
      120,
      14919,
      49,
      6536,
      120,
      21038,
      55114,
      43,
      49,
      41,
      409,
      32,
      48,
      44,
      730,
      1905,
      4072,
      32,
      49,
      44,
      1905,
      80427,
      359,
      120,
      21038,
      55114,
      43,
      49,
      41,
      409,
      32,
      48,
      11161,
      62,
      1905,
      409,
      17003,
      49,
      27680,
      43128,
      51,
      17093,
      50
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_curve",
    "text": "yÂ² = xÂ³ + b, and yÂ² = (xğœ‘)Â³ + b <=> yÂ² = xÂ³ + b (with ğœ‘Â³ == 1) so we are still on the curve",
    "token_ids": [
      121,
      21038,
      409,
      1905,
      41672,
      1349,
      287,
      44,
      306,
      330,
      21038,
      409,
      359,
      120,
      20968,
      156,
      145,
      41,
      41672,
      1349,
      287,
      11161,
      62,
      330,
      21038,
      409,
      1905,
      41672,
      1349,
      287,
      359,
      4953,
      32,
      20968,
      156,
      145,
      41672,
      2044,
      32,
      49,
      41,
      612,
      563,
      457,
      2235,
      375,
      275,
      15450
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_lambda",
    "text": "Î»áµ©Â² + Î»áµ© + 1 â‰¡ 0 (mod r) and ğœ‘Â² + ğœ‘ + 1 â‰¡ 0 (mod p)",
    "token_ids": [
      26046,
      134820,
      169,
      21038,
      1349,
      63233,
      134820,
      169,
      1349,
      32,
      49,
      159495,
      32,
      48,
      359,
      4898,
      354,
      41,
      306,
      32,
      20968,
      156,
      145,
      21038,
      1349,
      32,
      20968,
      156,
      145,
      1349,
      32,
      49,
      159495,
      32,
      48,
      359,
      4898,
      273,
      41
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_scalar",
    "text": "[a]P to represent P+P+ .... + P",
    "token_ids": [
      65323,
      93,
      80,
      301,
      3137,
      371,
      114010,
      43,
      51262,
      1349,
      371
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_bilinear",
    "text": "e: ğ”¾1 x ğ”¾2 -> ğ”¾t that map is bilinear e([a]P, [b]Q) = e(P, Q)áµƒáµ‡",
    "token_ids": [
      101,
      58,
      32,
      20968,
      148,
      190,
      49,
      1905,
      32,
      20968,
      148,
      190,
      50,
      3736,
      32,
      20968,
      148,
      190,
      116,
      389,
      5648,
      355,
      179816,
      316,
      9277,
      97,
      93,
      80,
      44,
      791,
      98,
      93,
      81,
      41,
      409,
      316,
      15284,
      44,
      1696,
      41,
      134820,
      131,
      134820,
      135
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_srs",
    "text": "srs_g1: [[1]â‚, [Ï„]â‚, [Ï„Â²]â‚, ... [Ï„â¿â»Â¹]â‚] also called powers of tau",
    "token_ids": [
      115,
      11686,
      11199,
      49,
      58,
      3724,
      49,
      93,
      73173,
      44,
      791,
      20669,
      93,
      73173,
      44,
      791,
      20669,
      21038,
      93,
      73173,
      44,
      4831,
      791,
      20669,
      39379,
      191,
      39379,
      187,
      83184,
      93,
      73173,
      93,
      964,
      3431,
      17370,
      300,
      53562
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_commitment",
    "text": "commit(srs_g1, blob) -> commitment C = âˆ‘ blobáµ¢.srs_g1áµ¢ = âˆ‘ [blobáµ¢.Ï„â±]â‚ = [p(Ï„)]â‚",
    "token_ids": [
      29566,
      3389,
      11686,
      11199,
      49,
      44,
      66949,
      41,
      3736,
      15095,
      347,
      409,
      15365,
      145,
      66949,
      134820,
      162,
      1411,
      11686,
      11199,
      49,
      134820,
      162,
      409,
      15365,
      145,
      791,
      28430,
      134820,
      162,
      46,
      20669,
      39379,
      177,
      93,
      73173,
      409,
      791,
      112,
      40,
      20669,
      18307,
      73173
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_witness",
    "text": "w(x, z) = (p(x) - p(z)) / (x-z)",
    "token_ids": [
      119,
      4704,
      44,
      1443,
      41,
      409,
      359,
      112,
      4704,
      41,
      661,
      273,
      21290,
      2261,
      1180,
      359,
      120,
      27658,
      41
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_verification",
    "text": "e([proof]â‚, [Ï„]â‚‚ - [z]â‚‚) = e(C - [y]â‚, [1]â‚‚)",
    "token_ids": [
      101,
      9277,
      18234,
      93,
      73173,
      44,
      791,
      20669,
      93,
      67671,
      661,
      791,
      122,
      93,
      67671,
      41,
      409,
      316,
      11193,
      661,
      791,
      121,
      93,
      73173,
      44,
      791,
      49,
      93,
      67671,
      41
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "ecc_lagrange",
    "text": "Ï‰ âˆˆ ğ”½r a root of unity of order n, i.e. Ï‰â¿ = 1",
    "token_ids": [
      35921,
      96957,
      32,
      20968,
      148,
      189,
      114,
      258,
      7724,
      300,
      32924,
      300,
      2417,
      311,
      44,
      1312,
      5318,
      46,
      125358,
      39379,
      191,
      409,
      32,
      49
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "group_basics",
    "text": "A group is a set of elements with a binary operation called the group law with a neutral element and an inverse.",
    "token_ids": [
      65,
      2746,
      355,
      258,
      1157,
      300,
      6387,
      418,
      258,
      14974,
      7311,
      3431,
      275,
      2746,
      2749,
      418,
      258,
      17497,
      4871,
      306,
      292,
      31633,
      46
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "field_basics",
    "text": "A field is a set of elements with two group laws, addition and multiplication, with corresponding inverse properties.",
    "token_ids": [
      65,
      2921,
      355,
      258,
      1157,
      300,
      6387,
      418,
      1451,
      2746,
      8349,
      44,
      4554,
      306,
      45271,
      44,
      418,
      9699,
      31633,
      7107,
      46
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "finite_field",
    "text": "ğ”½r is a finite-field of prime order r",
    "token_ids": [
      20968,
      148,
      189,
      114,
      355,
      258,
      20109,
      45471,
      300,
      7501,
      2417,
      354
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "cyclic_group",
    "text": "The group can be cyclic, i.e. all elements of the group can be generated by repeatedly applying the group law.",
    "token_ids": [
      758,
      2746,
      566,
      364,
      61652,
      44,
      1312,
      5318,
      46,
      679,
      6387,
      300,
      275,
      2746,
      566,
      364,
      9689,
      531,
      29211,
      16322,
      275,
      2746,
      2749,
      46
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "additive_notation",
    "text": "[a]P to represent P+P+ .... + P, applying the group law a times, i.e. the scalar multiplication.",
    "token_ids": [
      65323,
      93,
      80,
      301,
      3137,
      371,
      114010,
      43,
      51262,
      1349,
      371,
      44,
      16322,
      275,
      2746,
      2749,
      258,
      3539,
      44,
      1312,
      5318,
      46,
      275,
      36133,
      45271,
      46
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_prover",
    "text": "Prover computes witness polynomial w(x, z) = (p(x) - p(z)) / (x-z)",
    "token_ids": [
      1661,
      415,
      92329,
      12583,
      36552,
      282,
      4704,
      44,
      1443,
      41,
      409,
      359,
      112,
      4704,
      41,
      661,
      273,
      21290,
      2261,
      1180,
      359,
      120,
      27658,
      41
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_verifier",
    "text": "Verifier checks proof.(Ï„-z) = p(Ï„) - y using bilinear pairing",
    "token_ids": [
      131859,
      18899,
      11067,
      20210,
      20669,
      27658,
      41,
      409,
      273,
      40,
      20669,
      41,
      661,
      330,
      1818,
      179816,
      70489
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_fiat_shamir",
    "text": "To make the protocol non-interactive, z may be computed via the Fiat-Shamir heuristic.",
    "token_ids": [
      2455,
      1454,
      275,
      10345,
      2295,
      195515,
      44,
      1443,
      992,
      364,
      26826,
      4247,
      275,
      88011,
      46583,
      322,
      357,
      98364,
      46
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_schwartz",
    "text": "According to the Schwartz-zippel Lemma it is cryptographically unlikely that this equation holds",
    "token_ids": [
      13428,
      301,
      275,
      78833,
      27658,
      11994,
      295,
      32660,
      412,
      355,
      13018,
      69773,
      23788,
      389,
      546,
      12026,
      13364
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_srs_g1",
    "text": "srs_g1: [[1]â‚, [Ï„]â‚, [Ï„Â²]â‚, ... [Ï„â¿â»Â¹]â‚] also called powers of tau, with a bounded degree n-1",
    "token_ids": [
      115,
      11686,
      11199,
      49,
      58,
      3724,
      49,
      93,
      73173,
      44,
      791,
      20669,
      93,
      73173,
      44,
      791,
      20669,
      21038,
      93,
      73173,
      44,
      4831,
      791,
      20669,
      39379,
      191,
      39379,
      187,
      83184,
      93,
      73173,
      93,
      964,
      3431,
      17370,
      300,
      53562,
      44,
      418,
      258,
      36085,
      6959,
      311,
      45,
      49
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_srs_g2",
    "text": "srs_g2: [[1]â‚‚, [Ï„]â‚‚]",
    "token_ids": [
      115,
      11686,
      11199,
      50,
      58,
      3724,
      49,
      93,
      67671,
      44,
      791,
      20669,
      93,
      67671,
      93
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_trust_setup",
    "text": "Ï„ and its powers are secrets that no one knows, we only work with [Ï„â±]â‚ and [Ï„]â‚‚ not with Ï„ directly",
    "token_ids": [
      20669,
      306,
      1072,
      17370,
      457,
      29824,
      389,
      687,
      841,
      10824,
      44,
      563,
      1245,
      1002,
      418,
      791,
      20669,
      39379,
      177,
      93,
      73173,
      306,
      791,
      20669,
      93,
      67671,
      516,
      418,
      32345,
      6467
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "pcs_monomial",
    "text": "p(x) = blobâ‚€ + blobâ‚ x + blobâ‚‚ xÂ² + ... + blobâ‚™â‚‹â‚ xâ¿â»Â¹",
    "token_ids": [
      112,
      4704,
      41,
      409,
      66949,
      177094,
      1349,
      66949,
      73173,
      1905,
      1349,
      66949,
      67671,
      1905,
      21038,
      1349,
      4831,
      1349,
      66949,
      30288,
      153,
      30288,
      139,
      73173,
      1905,
      39379,
      191,
      39379,
      187,
      83184
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  },
  {
    "name": "sanguozhi_paragraph",
    "text": "ç´…ã€‚ç™½\né«®æ¼æ¨µæ±Ÿæ¸šä¸Šï¼Œæ…£çœ‹ç§‹æœˆæ˜¥é¢¨ã€‚ä¸€å£ºæ¿é…’å–œç›¸é€¢ï¼šå¤ä»Šå¤šå°‘äº‹ï¼Œéƒ½ä»˜ç¬‘è«‡ä¸­ã€‚\n\nã€€ã€€è©±èªªå¤©ä¸‹å¤§å‹¢ï¼Œåˆ†ä¹…å¿…åˆï¼Œåˆä¹…å¿…åˆ†ï¼šå‘¨æœ«ä¸ƒåœ‹åˆ†çˆ­ï¼Œå¹¶å…¥æ–¼ç§¦ã€‚åŠç§¦æ»…ä¹‹å¾Œï¼Œæ¥š\nã€æ¼¢åˆ†çˆ­ï¼Œåˆå¹¶å…¥æ–¼æ¼¢ã€‚æ¼¢æœè‡ªé«˜ç¥–æ–¬ç™½è›‡è€Œèµ·ç¾©ï¼Œä¸€çµ±å¤©ä¸‹ã€‚å¾Œä¾†å…‰æ­¦ä¸­èˆˆï¼Œå‚³è‡³ç»\nå¸ï¼Œé‚åˆ†ç‚ºä¸‰åœ‹ã€‚æ¨å…¶è‡´äº‚ä¹‹ç”±ï¼Œæ®†å§‹æ–¼æ¡“ã€éˆäºŒå¸ã€‚æ¡“å¸ç¦éŒ®å–„é¡ï¼Œå´‡ä¿¡å®¦å®˜ã€‚åŠæ¡“\nå¸å´©ï¼Œéˆå¸å³ä½ï¼Œå¤§å°‡è»ç«‡æ­¦ã€å¤ªå‚…é™³è•ƒï¼Œå…±ç›¸è¼”ä½ã€‚æ™‚",
    "token_ids": [
      40809,
      74964,
      10,
      1123,
      174,
      72333,
      195066,
      4471,
      189381,
      743,
      321,
      25144,
      1391,
      9568,
      1400,
      6236,
      10789,
      12169,
      1499,
      186,
      188617,
      5510,
      4456,
      175091,
      861,
      132888,
      11128,
      1106,
      10354,
      3798,
      4224,
      9959,
      700,
      3013,
      3466,
      3466,
      5539,
      28631,
      20448,
      185556,
      35241,
      6469,
      2643,
      1152,
      114579,
      6469,
      2643,
      968,
      861,
      53399,
      7266,
      15233,
      968,
      87419,
      4572,
      1395,
      18513,
      13035,
      350,
      1974,
      13035,
      50268,
      136577,
      89282,
      10,
      387,
      43479,
      968,
      87419,
      9635,
      2172,
      1395,
      18513,
      43479,
      350,
      43479,
      6257,
      927,
      1169,
      13334,
      141183,
      2885,
      26306,
      90525,
      14802,
      3535,
      15715,
      20448,
      152317,
      20525,
      2755,
      5796,
      700,
      17923,
      321,
      63348,
      2999,
      190761,
      10,
      9264,
      98844,
      968,
      10179,
      1803,
      15233,
      350,
      3487,
      1575,
      4550,
      187796,
      1318,
      2362,
      321,
      83158,
      3002,
      18513,
      90004,
      387,
      160727,
      2137,
      9264,
      350,
      90004,
      9264,
      10056,
      8328,
      174,
      5548,
      9628,
      321,
      25141,
      1814,
      138777,
      5972,
      350,
      1974,
      90004,
      10,
      9264,
      23922,
      321,
      160727,
      9264,
      185472,
      8501,
      31059,
      23566,
      1058,
      135,
      5796,
      100015,
      27223,
      69179,
      141545,
      37124,
      1671,
      133560,
      21135,
      350,
      2341
    ],
    "tokenizer": "minimax-m2.1-tokenizer.json"
  }
]