[
  {
    "name": "chinese",
    "text": "‰Ω†Â•Ω‰∏ñÁïå",
    "token_ids": [
      57668,
      53901,
      102616
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "japanese",
    "text": "„Åì„Çì„Å´„Å°„ÅØ",
    "token_ids": [
      90115
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "korean",
    "text": "ÏïàÎÖïÌïòÏÑ∏Ïöî ÏÑ∏Í≥Ñ",
    "token_ids": [
      101193,
      124409,
      110572
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "russian",
    "text": "–ü—Ä–∏–≤–µ—Ç –º–∏—Ä",
    "token_ids": [
      54745,
      28089,
      8341,
      115388
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "hebrew",
    "text": "◊©◊ú◊ï◊ù ◊¢◊ï◊ú◊ù",
    "token_ids": [
      59511,
      50391,
      37769,
      251,
      17732,
      95,
      37769,
      250,
      147,
      251
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "khmer",
    "text": "·ûü·ûΩ·ûü·üí·ûè·û∏·ûñ·û∑·ûó·ûñ·ûõ·üÑ·ûÄ",
    "token_ids": [
      21549,
      253,
      21549,
      121,
      21549,
      253,
      73673,
      237,
      21549,
      116,
      21549,
      244,
      21549,
      115,
      21549,
      245,
      21549,
      244,
      21549,
      249,
      45358,
      226,
      21549,
      222
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "emoji",
    "text": "Hello üåç World! üéâ",
    "token_ids": [
      9906,
      11410,
      234,
      235,
      4435,
      0,
      11410,
      236,
      231
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "mixed_cjk",
    "text": "Hello ‰∏ñÁïå „Åì„Çì„Å´„Å°„ÅØ ÏïàÎÖï",
    "token_ids": [
      9906,
      127365,
      220,
      90115,
      96270,
      116024
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "hello_world",
    "text": "Hello, world!",
    "token_ids": [
      9906,
      11,
      1917,
      0
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "greek_basic",
    "text": "ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨ Œ∫Œ±Œπ ŒºŒ±Œ∏Œ∑ŒºŒ±œÑŒπŒ∫Œ¨",
    "token_ids": [
      100477,
      109164,
      102434,
      100429,
      105290,
      101733,
      100432,
      103643
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "greek_alphabet",
    "text": "Œë Œ± Œí Œ≤ Œì Œ≥ Œî Œ¥ Œï Œµ Œñ Œ∂ Œó Œ∑ Œò Œ∏ Œô Œπ Œö Œ∫ Œõ Œª Œú Œº Œù ŒΩ Œû Œæ Œü Œø Œ† œÄ Œ° œÅ Œ£ œÉ Œ§ œÑ Œ• œÖ Œ¶ œÜ Œß œá Œ® œà Œ© œâ",
    "token_ids": [
      100341,
      19581,
      101078,
      34318,
      85316,
      63127,
      82263,
      70434,
      100567,
      60247,
      107941,
      105092,
      101874,
      101034,
      103068,
      101174,
      101651,
      102703,
      100503,
      72738,
      101749,
      49438,
      100552,
      33983,
      101288,
      99786,
      114423,
      104679,
      101137,
      100544,
      100468,
      52845,
      103174,
      17839,
      223,
      100545,
      48823,
      100671,
      39570,
      104118,
      101496,
      101989,
      98975,
      101895,
      100897,
      120184,
      112091,
      117336,
      117774
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_endo",
    "text": "Check the Endomorphism for p mod 3 == 1",
    "token_ids": [
      4061,
      279,
      4060,
      316,
      53907,
      369,
      281,
      1491,
      220,
      18,
      624,
      220,
      16
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_cube_roots",
    "text": "x¬≥‚àí1=0 <=> (x‚àí1)(x¬≤+x+1) = 0, if x != 1, x solves (x¬≤+x+1) = 0 <=> x = (-1¬±‚àö3)/2",
    "token_ids": [
      87,
      44301,
      34363,
      16,
      28,
      15,
      72605,
      320,
      87,
      34363,
      16,
      2432,
      87,
      30556,
      38992,
      10,
      16,
      8,
      284,
      220,
      15,
      11,
      422,
      865,
      976,
      220,
      16,
      11,
      865,
      68577,
      320,
      87,
      30556,
      38992,
      10,
      16,
      8,
      284,
      220,
      15,
      72605,
      865,
      284,
      10505,
      16,
      38121,
      110682,
      18,
      5738,
      17
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_curve",
    "text": "y¬≤ = x¬≥ + b, and y¬≤ = (xùúë)¬≥ + b <=> y¬≤ = x¬≥ + b (with ùúë¬≥ == 1) so we are still on the curve",
    "token_ids": [
      88,
      30556,
      284,
      865,
      44301,
      489,
      293,
      11,
      323,
      379,
      30556,
      284,
      320,
      87,
      57352,
      250,
      239,
      8,
      44301,
      489,
      293,
      72605,
      379,
      30556,
      284,
      865,
      44301,
      489,
      293,
      320,
      4291,
      82350,
      250,
      239,
      44301,
      624,
      220,
      16,
      8,
      779,
      584,
      527,
      2103,
      389,
      279,
      16029
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_lambda",
    "text": "Œª·µ©¬≤ + Œª·µ© + 1 ‚â° 0 (mod r) and ùúë¬≤ + ùúë + 1 ‚â° 0 (mod p)",
    "token_ids": [
      34586,
      157,
      113,
      102,
      30556,
      489,
      49438,
      157,
      113,
      102,
      489,
      220,
      16,
      21784,
      94,
      220,
      15,
      320,
      2658,
      436,
      8,
      323,
      82350,
      250,
      239,
      30556,
      489,
      82350,
      250,
      239,
      489,
      220,
      16,
      21784,
      94,
      220,
      15,
      320,
      2658,
      281,
      8
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_scalar",
    "text": "[a]P to represent P+P+ .... + P",
    "token_ids": [
      15848,
      60,
      47,
      311,
      4097,
      393,
      10,
      47,
      10,
      22666,
      489,
      393
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_bilinear",
    "text": "e: ùîæ1 x ùîæ2 -> ùîæt that map is bilinear e([a]P, [b]Q) = e(P, Q)·µÉ·µá",
    "token_ids": [
      68,
      25,
      82350,
      242,
      122,
      16,
      865,
      82350,
      242,
      122,
      17,
      1492,
      82350,
      242,
      122,
      83,
      430,
      2472,
      374,
      20934,
      90021,
      384,
      2625,
      64,
      60,
      47,
      11,
      510,
      65,
      60,
      48,
      8,
      284,
      384,
      5417,
      11,
      1229,
      8,
      157,
      113,
      225,
      157,
      113,
      229
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_srs",
    "text": "srs_g1: [[1]‚ÇÅ, [œÑ]‚ÇÅ, [œÑ¬≤]‚ÇÅ, ... [œÑ‚Åø‚Åª¬π]‚ÇÅ] also called powers of tau",
    "token_ids": [
      82,
      5544,
      1928,
      16,
      25,
      4416,
      16,
      60,
      32086,
      11,
      510,
      36924,
      60,
      32086,
      11,
      510,
      36924,
      30556,
      60,
      32086,
      11,
      2564,
      510,
      36924,
      53233,
      123,
      53233,
      119,
      60597,
      60,
      32086,
      60,
      1101,
      2663,
      13736,
      315,
      32923
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_commitment",
    "text": "commit(srs_g1, blob) -> commitment C = ‚àë blob·µ¢.srs_g1·µ¢ = ‚àë [blob·µ¢.œÑ‚Å±]‚ÇÅ = [p(œÑ)]‚ÇÅ",
    "token_ids": [
      17869,
      1161,
      5544,
      1928,
      16,
      11,
      24295,
      8,
      1492,
      15507,
      356,
      284,
      12264,
      239,
      24295,
      157,
      113,
      95,
      516,
      5544,
      1928,
      16,
      157,
      113,
      95,
      284,
      12264,
      239,
      510,
      36212,
      157,
      113,
      95,
      13,
      36924,
      53233,
      109,
      60,
      32086,
      284,
      510,
      79,
      7,
      36924,
      7400,
      32086
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_witness",
    "text": "w(x, z) = (p(x) - p(z)) / (x-z)",
    "token_ids": [
      86,
      2120,
      11,
      1167,
      8,
      284,
      320,
      79,
      2120,
      8,
      482,
      281,
      13476,
      595,
      611,
      320,
      87,
      9319,
      8
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_verification",
    "text": "e([proof]‚ÇÅ, [œÑ]‚ÇÇ - [z]‚ÇÇ) = e(C - [y]‚ÇÅ, [1]‚ÇÇ)",
    "token_ids": [
      68,
      2625,
      16157,
      60,
      32086,
      11,
      510,
      36924,
      60,
      32907,
      482,
      510,
      89,
      60,
      32907,
      8,
      284,
      384,
      3100,
      482,
      510,
      88,
      60,
      32086,
      11,
      510,
      16,
      60,
      32907,
      8
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "ecc_lagrange",
    "text": "œâ ‚àà ùîΩr a root of unity of order n, i.e. œâ‚Åø = 1",
    "token_ids": [
      57971,
      49435,
      82350,
      242,
      121,
      81,
      264,
      3789,
      315,
      31426,
      315,
      2015,
      308,
      11,
      602,
      1770,
      13,
      117774,
      53233,
      123,
      284,
      220,
      16
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "group_basics",
    "text": "A group is a set of elements with a binary operation called the group law with a neutral element and an inverse.",
    "token_ids": [
      32,
      1912,
      374,
      264,
      743,
      315,
      5540,
      449,
      264,
      8026,
      5784,
      2663,
      279,
      1912,
      2383,
      449,
      264,
      21277,
      2449,
      323,
      459,
      29049,
      13
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "field_basics",
    "text": "A field is a set of elements with two group laws, addition and multiplication, with corresponding inverse properties.",
    "token_ids": [
      32,
      2115,
      374,
      264,
      743,
      315,
      5540,
      449,
      1403,
      1912,
      7016,
      11,
      5369,
      323,
      47544,
      11,
      449,
      12435,
      29049,
      6012,
      13
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "finite_field",
    "text": "ùîΩr is a finite-field of prime order r",
    "token_ids": [
      57352,
      242,
      121,
      81,
      374,
      264,
      35326,
      19677,
      315,
      10461,
      2015,
      436
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "cyclic_group",
    "text": "The group can be cyclic, i.e. all elements of the group can be generated by repeatedly applying the group law.",
    "token_ids": [
      791,
      1912,
      649,
      387,
      77102,
      11,
      602,
      1770,
      13,
      682,
      5540,
      315,
      279,
      1912,
      649,
      387,
      8066,
      555,
      19352,
      19486,
      279,
      1912,
      2383,
      13
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "additive_notation",
    "text": "[a]P to represent P+P+ .... + P, applying the group law a times, i.e. the scalar multiplication.",
    "token_ids": [
      15848,
      60,
      47,
      311,
      4097,
      393,
      10,
      47,
      10,
      22666,
      489,
      393,
      11,
      19486,
      279,
      1912,
      2383,
      264,
      3115,
      11,
      602,
      1770,
      13,
      279,
      17722,
      47544,
      13
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_prover",
    "text": "Prover computes witness polynomial w(x, z) = (p(x) - p(z)) / (x-z)",
    "token_ids": [
      1360,
      424,
      58303,
      11550,
      48411,
      289,
      2120,
      11,
      1167,
      8,
      284,
      320,
      79,
      2120,
      8,
      482,
      281,
      13476,
      595,
      611,
      320,
      87,
      9319,
      8
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_verifier",
    "text": "Verifier checks proof.(œÑ-z) = p(œÑ) - y using bilinear pairing",
    "token_ids": [
      83494,
      12621,
      11311,
      13127,
      36924,
      9319,
      8,
      284,
      281,
      7,
      36924,
      8,
      482,
      379,
      1701,
      20934,
      90021,
      48813
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_fiat_shamir",
    "text": "To make the protocol non-interactive, z may be computed via the Fiat-Shamir heuristic.",
    "token_ids": [
      1271,
      1304,
      279,
      11766,
      2536,
      12,
      38640,
      11,
      1167,
      1253,
      387,
      25157,
      4669,
      279,
      70399,
      31361,
      309,
      404,
      67709,
      13
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_schwartz",
    "text": "According to the Schwartz-zippel Lemma it is cryptographically unlikely that this equation holds",
    "token_ids": [
      11439,
      311,
      279,
      65885,
      9319,
      2877,
      301,
      86910,
      433,
      374,
      14774,
      65031,
      17821,
      430,
      420,
      24524,
      10187
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_srs_g1",
    "text": "srs_g1: [[1]‚ÇÅ, [œÑ]‚ÇÅ, [œÑ¬≤]‚ÇÅ, ... [œÑ‚Åø‚Åª¬π]‚ÇÅ] also called powers of tau, with a bounded degree n-1",
    "token_ids": [
      82,
      5544,
      1928,
      16,
      25,
      4416,
      16,
      60,
      32086,
      11,
      510,
      36924,
      60,
      32086,
      11,
      510,
      36924,
      30556,
      60,
      32086,
      11,
      2564,
      510,
      36924,
      53233,
      123,
      53233,
      119,
      60597,
      60,
      32086,
      60,
      1101,
      2663,
      13736,
      315,
      32923,
      11,
      449,
      264,
      62215,
      8547,
      308,
      12,
      16
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_srs_g2",
    "text": "srs_g2: [[1]‚ÇÇ, [œÑ]‚ÇÇ]",
    "token_ids": [
      82,
      5544,
      1928,
      17,
      25,
      4416,
      16,
      60,
      32907,
      11,
      510,
      36924,
      60,
      32907,
      60
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_trust_setup",
    "text": "œÑ and its powers are secrets that no one knows, we only work with [œÑ‚Å±]‚ÇÅ and [œÑ]‚ÇÇ not with œÑ directly",
    "token_ids": [
      36924,
      323,
      1202,
      13736,
      527,
      24511,
      430,
      912,
      832,
      8964,
      11,
      584,
      1193,
      990,
      449,
      510,
      36924,
      53233,
      109,
      60,
      32086,
      323,
      510,
      36924,
      60,
      32907,
      539,
      449,
      39570,
      6089
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "pcs_monomial",
    "text": "p(x) = blob‚ÇÄ + blob‚ÇÅ x + blob‚ÇÇ x¬≤ + ... + blob‚Çô‚Çã‚ÇÅ x‚Åø‚Åª¬π",
    "token_ids": [
      79,
      2120,
      8,
      284,
      24295,
      90769,
      489,
      24295,
      32086,
      865,
      489,
      24295,
      32907,
      865,
      30556,
      489,
      2564,
      489,
      24295,
      16275,
      247,
      16275,
      233,
      32086,
      865,
      53233,
      123,
      53233,
      119,
      60597
    ],
    "tokenizer": "llama3-tokenizer.json"
  },
  {
    "name": "sanguozhi_paragraph",
    "text": "Á¥Ö„ÄÇÁôΩ\nÈ´ÆÊºÅÊ®µÊ±üÊ∏ö‰∏äÔºåÊÖ£ÁúãÁßãÊúàÊò•È¢®„ÄÇ‰∏ÄÂ£∫ÊøÅÈÖíÂñúÁõ∏ÈÄ¢ÔºöÂè§‰ªäÂ§öÂ∞ë‰∫ãÔºåÈÉΩ‰ªòÁ¨ëË´á‰∏≠„ÄÇ\n\n„ÄÄ„ÄÄË©±Ë™™Â§©‰∏ãÂ§ßÂã¢ÔºåÂàÜ‰πÖÂøÖÂêàÔºåÂêà‰πÖÂøÖÂàÜÔºöÂë®Êú´‰∏ÉÂúãÂàÜÁà≠ÔºåÂπ∂ÂÖ•ÊñºÁß¶„ÄÇÂèäÁß¶ÊªÖ‰πãÂæåÔºåÊ•ö\n„ÄÅÊº¢ÂàÜÁà≠ÔºåÂèàÂπ∂ÂÖ•ÊñºÊº¢„ÄÇÊº¢ÊúùËá™È´òÁ•ñÊñ¨ÁôΩËõáËÄåËµ∑Áæ©Ôºå‰∏ÄÁµ±Â§©‰∏ã„ÄÇÂæå‰æÜÂÖâÊ≠¶‰∏≠ËààÔºåÂÇ≥Ëá≥Áçª\nÂ∏ùÈÅÇÂàÜÁÇ∫‰∏âÂúã„ÄÇÊé®ÂÖ∂Ëá¥‰∫Ç‰πãÁî±ÔºåÊÆÜÂßãÊñºÊ°ì„ÄÅÈùà‰∫åÂ∏ù„ÄÇÊ°ìÂ∏ùÁ¶ÅÈåÆÂñÑÈ°ûÔºåÂ¥á‰ø°ÂÆ¶ÂÆò„ÄÇÂèäÊ°ì\nÂ∏ùÂ¥©ÔºåÈùàÂ∏ùÂç≥‰ΩçÔºåÂ§ßÂ∞áËªçÁ´áÊ≠¶",
    "token_ids": [
      113000,
      1811,
      101828,
      198,
      100499,
      106,
      78256,
      223,
      100762,
      113,
      70277,
      35086,
      248,
      17905,
      3922,
      101557,
      96,
      52030,
      107795,
      9953,
      104149,
      104346,
      115397,
      45826,
      118,
      102754,
      223,
      103882,
      104940,
      50021,
      11589,
      95,
      5232,
      102491,
      37271,
      115251,
      30926,
      120241,
      47000,
      49838,
      111813,
      16325,
      3490,
      23249,
      23249,
      87177,
      106336,
      36827,
      17297,
      27384,
      110095,
      3922,
      17620,
      101704,
      59614,
      40862,
      3922,
      40862,
      101704,
      59614,
      17620,
      5232,
      41642,
      106968,
      103305,
      101257,
      17620,
      124271,
      91495,
      17701,
      102572,
      120006,
      1811,
      82317,
      120006,
      121143,
      55030,
      74482,
      3922,
      112406,
      198,
      5486,
      115953,
      17620,
      124271,
      113711,
      64026,
      17701,
      102572,
      115953,
      1811,
      115953,
      103293,
      37026,
      45736,
      111656,
      7741,
      105,
      101828,
      127618,
      69636,
      72718,
      104577,
      104295,
      105156,
      36827,
      17297,
      1811,
      74482,
      102993,
      101426,
      103787,
      16325,
      109834,
      3922,
      109365,
      57237,
      103198,
      119,
      198,
      106152,
      30250,
      224,
      17620,
      101399,
      46091,
      101257,
      1811,
      84851,
      42246,
      105260,
      6823,
      224,
      55030,
      68171,
      3922,
      36149,
      228,
      27704,
      102572,
      44559,
      241,
      5486,
      126321,
      41920,
      106152,
      1811,
      44559,
      241,
      106152,
      108493,
      91779,
      106,
      106594,
      104770,
      3922,
      125042,
      22023,
      8676,
      99,
      102078,
      1811,
      82317,
      44559,
      241,
      198,
      106152,
      103553,
      102,
      3922,
      126321,
      106152,
      92776,
      25129,
      112886,
      106812,
      103472,
      25781,
      229,
      103787
    ],
    "tokenizer": "llama3-tokenizer.json"
  }
]